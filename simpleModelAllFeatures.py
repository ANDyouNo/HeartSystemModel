import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    roc_auc_score, average_precision_score, f1_score,
    classification_report, confusion_matrix
)
from sklearn.calibration import CalibratedClassifierCV
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Tuple, List
import joblib
import warnings
warnings.filterwarnings('ignore')


class MultiLabelCardioClassifier:
    """
    –ú—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–∞—Ä–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ XGBoost
    —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–¥–±–æ—Ä–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –æ—Ü–µ–Ω–∫–æ–π —Ä–∏—Å–∫–æ–≤
    """
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.diseases = [
            '–î–∏—Å–ª–∏–ø–∏–¥–µ–º–∏—è',
            '–ê—Ç–µ—Ä–æ—Å–∫–ª–µ—Ä–æ–∑',
            '–ú–µ—Ç–∞–±–æ–ª–∏—á–µ—Å–∫–∏–π —Å–∏–Ω–¥—Ä–æ–º',
            '–°–∞—Ö–∞—Ä–Ω—ã–π –¥–∏–∞–±–µ—Ç',
            '–•–°–ù',
            '–ú–∏–æ–ø–∞—Ç–∏—è',
            '–ü–æ—Å—Ç—Å—Ç—Ä–µ–ø—Ç–æ–∫–æ–∫–∫–æ–≤—ã–π –∫–∞—Ä–¥–∏—Ç',
            '–†–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ª–∏—Ö–æ—Ä–∞–¥–∫–∞',
            '–ê—Ç–µ—Ä–æ—Å–∫–ª–µ—Ä–æ—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ä–¥–∏–æ–ø–∞—Ç–∏—è',
            '–ê–Ω–µ–º–∏—è',
            '–≠–ª–µ–∫—Ç—Ä–æ–ª–∏—Ç–Ω—ã–µ –∞—Ä–∏—Ç–º–∏–∏',
            '–ê–ª–∫–æ–≥–æ–ª—å–Ω–∞—è –∫–∞—Ä–¥–∏–æ–º–∏–æ–ø–∞—Ç–∏—è'
        ]
        
        self.models = {}
        self.calibrated_models = {}
        self.scalers = {}
        self.best_params = {}
        self.optimal_thresholds = {}
        self.feature_importance = {}
        
        # –í–µ—Å–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞ (–ø–æ —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è)
        self.disease_weights = {
            '–î–∏—Å–ª–∏–ø–∏–¥–µ–º–∏—è': 0.6,
            '–ê—Ç–µ—Ä–æ—Å–∫–ª–µ—Ä–æ–∑': 0.9,
            '–ú–µ—Ç–∞–±–æ–ª–∏—á–µ—Å–∫–∏–π —Å–∏–Ω–¥—Ä–æ–º': 0.8,
            '–°–∞—Ö–∞—Ä–Ω—ã–π –¥–∏–∞–±–µ—Ç': 0.85,
            '–•–°–ù': 1.0,
            '–ú–∏–æ–ø–∞—Ç–∏—è': 0.7,
            '–ü–æ—Å—Ç—Å—Ç—Ä–µ–ø—Ç–æ–∫–æ–∫–∫–æ–≤—ã–π –∫–∞—Ä–¥–∏—Ç': 0.85,
            '–†–µ–≤–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ª–∏—Ö–æ—Ä–∞–¥–∫–∞': 0.9,
            '–ê—Ç–µ—Ä–æ—Å–∫–ª–µ—Ä–æ—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ä–¥–∏–æ–ø–∞—Ç–∏—è': 0.95,
            '–ê–Ω–µ–º–∏—è': 0.5,
            '–≠–ª–µ–∫—Ç—Ä–æ–ª–∏—Ç–Ω—ã–µ –∞—Ä–∏—Ç–º–∏–∏': 0.8,
            '–ê–ª–∫–æ–≥–æ–ª—å–Ω–∞—è –∫–∞—Ä–¥–∏–æ–º–∏–æ–ø–∞—Ç–∏—è': 0.95
        }
        
    def prepare_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –º–µ—Ç–∫–∏"""
        # –ü—Ä–∏–∑–Ω–∞–∫–∏
        feature_cols = [col for col in df.columns if col not in self.diseases]
        X = df[feature_cols].copy()
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–∞
        X['–ü–æ–ª'] = X['–ü–æ–ª'].map({'–ú': 1, '–ñ': 0})
        
        # –ú–µ—Ç–∫–∏
        y = df[self.diseases].copy()
        
        return X, y
    
    def find_optimal_iterations(self, X_train, y_train, disease: str) -> Dict:
        """
        –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º early stopping
        """
        print(f"\n{'='*60}")
        print(f"–ü–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è: {disease}")
        print(f"{'='*60}")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/validation
        X_tr, X_val, y_tr, y_val = train_test_split(
            X_train, y_train, test_size=0.2, random_state=self.random_state,
            stratify=y_train
        )
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        base_params = {
            'objective': 'binary:logistic',
            'eval_metric': 'auc',
            'random_state': self.random_state,
            'tree_method': 'hist',
            'max_depth': 6,
            'learning_rate': 0.05,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'min_child_weight': 3,
            'gamma': 0.1,
            'reg_alpha': 0.1,
            'reg_lambda': 1.0
        }
        
        # –í—ã—á–∏—Å–ª—è–µ–º scale_pos_weight –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤
        pos_count = y_tr.sum()
        neg_count = len(y_tr) - pos_count
        scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1.0
        base_params['scale_pos_weight'] = scale_pos_weight
        
        print(f"Scale pos weight: {scale_pos_weight:.2f}")
        print(f"Positive samples: {pos_count} ({pos_count/len(y_tr)*100:.1f}%)")
        
        # –°–æ–∑–¥–∞–µ–º DMatrix
        dtrain = xgb.DMatrix(X_tr, label=y_tr)
        dval = xgb.DMatrix(X_val, label=y_val)
        
        evals = [(dtrain, 'train'), (dval, 'eval')]
        
        # –û–±—É—á–µ–Ω–∏–µ —Å early stopping
        evals_result = {}
        model = xgb.train(
            base_params,
            dtrain,
            num_boost_round=2000,
            evals=evals,
            early_stopping_rounds=50,
            evals_result=evals_result,
            verbose_eval=False
        )
        
        best_iteration = model.best_iteration
        best_score = model.best_score
        
        print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π: {best_iteration}")
        print(f"–õ—É—á—à–∏–π AUC: {best_score:.4f}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ learning_rate –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–π
        if best_iteration < 200:
            base_params['learning_rate'] = 0.1
        elif best_iteration > 800:
            base_params['learning_rate'] = 0.03
        
        base_params['n_estimators'] = best_iteration
        
        return base_params
    
    def find_optimal_threshold(self, y_true, y_pred_proba) -> float:
        """
        –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ F1-score
        """
        thresholds = np.arange(0.1, 0.9, 0.01)
        f1_scores = []
        
        for threshold in thresholds:
            y_pred = (y_pred_proba >= threshold).astype(int)
            f1 = f1_score(y_true, y_pred, zero_division=0)
            f1_scores.append(f1)
        
        optimal_idx = np.argmax(f1_scores)
        optimal_threshold = thresholds[optimal_idx]
        optimal_f1 = f1_scores[optimal_idx]
        
        return optimal_threshold
    
    def train(self, X: pd.DataFrame, y: pd.DataFrame, test_size=0.2):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è
        """
        print("\n" + "="*80)
        print("–ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø –ú–£–õ–¨–¢–ò–õ–ï–ô–ë–õ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê")
        print("="*80)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state
        )
        
        print(f"\n–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_train)}")
        print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_test)}")
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("\n–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        scaler = StandardScaler()
        X_train_scaled = pd.DataFrame(
            scaler.fit_transform(X_train),
            columns=X_train.columns,
            index=X_train.index
        )
        X_test_scaled = pd.DataFrame(
            scaler.transform(X_test),
            columns=X_test.columns,
            index=X_test.index
        )
        self.scalers['main'] = scaler
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è
        results = {}
        
        for disease in self.diseases:
            print(f"\n{'#'*80}")
            print(f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è: {disease}")
            print(f"{'#'*80}")
            
            y_train_disease = y_train[disease]
            y_test_disease = y_test[disease]
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
            if y_train_disease.sum() < 10:
                print(f"‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è {disease}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            # –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            best_params = self.find_optimal_iterations(
                X_train_scaled, y_train_disease, disease
            )
            self.best_params[disease] = best_params
            
            # –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            print("\n–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
            model = xgb.XGBClassifier(**best_params, early_stopping_rounds=50)
            model.fit(
                X_train_scaled, y_train_disease,
                eval_set=[(X_test_scaled, y_test_disease)],
                verbose=False
            )
            
            self.models[disease] = model
            
            # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (—Å–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –±–µ–∑ early stopping)
            print("–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π...")
            calibration_params = best_params.copy()
            # –£–±–∏—Ä–∞–µ–º early_stopping_rounds –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
            model_for_calibration = xgb.XGBClassifier(**calibration_params)
            
            calibrated_model = CalibratedClassifierCV(
                model_for_calibration, method='sigmoid', cv=3
            )
            calibrated_model.fit(X_train_scaled, y_train_disease)
            self.calibrated_models[disease] = calibrated_model
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
            y_pred_proba = calibrated_model.predict_proba(X_test_scaled)[:, 1]
            
            # –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
            optimal_threshold = self.find_optimal_threshold(
                y_test_disease, y_pred_proba
            )
            self.optimal_thresholds[disease] = optimal_threshold
            
            y_pred = (y_pred_proba >= optimal_threshold).astype(int)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            auc = roc_auc_score(y_test_disease, y_pred_proba)
            ap = average_precision_score(y_test_disease, y_pred_proba)
            f1 = f1_score(y_test_disease, y_pred)
            
            results[disease] = {
                'AUC': auc,
                'AP': ap,
                'F1': f1,
                'Threshold': optimal_threshold,
                'Iterations': best_params['n_estimators']
            }
            
            print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
            print(f"   AUC: {auc:.4f}")
            print(f"   Average Precision: {ap:.4f}")
            print(f"   F1-Score: {f1:.4f}")
            print(f"   –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.3f}")
            
            # Feature importance
            self.feature_importance[disease] = pd.DataFrame({
                'feature': X_train.columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
        
        # –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._print_summary(results)
        
        return results
    
    def _print_summary(self, results: Dict):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        print("\n" + "="*80)
        print("–ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø")
        print("="*80)
        
        results_df = pd.DataFrame(results).T
        results_df = results_df.sort_values('AUC', ascending=False)
        
        print("\n" + results_df.to_string())
        
        print(f"\nüìà –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏:")
        print(f"   –°—Ä–µ–¥–Ω–∏–π AUC: {results_df['AUC'].mean():.4f}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π AP: {results_df['AP'].mean():.4f}")
        print(f"   –°—Ä–µ–¥–Ω–∏–π F1: {results_df['F1'].mean():.4f}")
    
    def predict_probabilities(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –≤—Å–µ—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π
        """
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        X_scaled = pd.DataFrame(
            self.scalers['main'].transform(X),
            columns=X.columns,
            index=X.index
        )
        
        probabilities = {}
        
        for disease in self.diseases:
            if disease in self.calibrated_models:
                proba = self.calibrated_models[disease].predict_proba(X_scaled)[:, 1]
                probabilities[disease] = proba
            else:
                probabilities[disease] = np.zeros(len(X))
        
        return pd.DataFrame(probabilities, index=X.index)
    
    def predict(self, X: pd.DataFrame) -> pd.DataFrame:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
        """
        probabilities = self.predict_probabilities(X)
        predictions = pd.DataFrame(index=X.index)
        
        for disease in self.diseases:
            if disease in self.optimal_thresholds:
                threshold = self.optimal_thresholds[disease]
                predictions[disease] = (probabilities[disease] >= threshold).astype(int)
            else:
                predictions[disease] = 0
        
        return predictions
    
    def calculate_risk_score(self, probabilities: pd.DataFrame) -> pd.DataFrame:
        """
        –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —Ä–∏—Å–∫–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã —Ä–∏—Å–∫–∞
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫ —Å—Ä–µ–¥–∏ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –∏ –∏—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏—é
        """
        risk_scores = []
        risk_categories = []
        
        for idx in probabilities.index:
            # –ú–µ—Ç–æ–¥ 1: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
            max_weighted_risk = 0
            
            for disease in self.diseases:
                if disease in probabilities.columns:
                    prob = probabilities.loc[idx, disease]
                    weight = self.disease_weights[disease]
                    weighted_risk = prob * weight * 100
                    max_weighted_risk = max(max_weighted_risk, weighted_risk)
            
            # –ú–µ—Ç–æ–¥ 2: –£—á–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π
            high_risk_count = 0
            moderate_risk_count = 0
            
            for disease in self.diseases:
                if disease in probabilities.columns:
                    prob = probabilities.loc[idx, disease]
                    if prob >= 0.5:
                        high_risk_count += 1
                    elif prob >= 0.3:
                        moderate_risk_count += 1
            
            # –ë–∞–∑–æ–≤—ã–π —Ä–∏—Å–∫
            base_risk = max_weighted_risk
            
            # –ë–æ–Ω—É—Å –∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è
            if high_risk_count >= 2:
                combo_bonus = (high_risk_count - 1) * 12
                base_risk = min(100, base_risk + combo_bonus)
            
            if moderate_risk_count >= 2:
                combo_bonus = (moderate_risk_count - 1) * 5
                base_risk = min(100, base_risk + combo_bonus)
            
            risk_score = base_risk
            risk_scores.append(risk_score)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä–∏—Å–∫–∞
            if risk_score >= 65:
                category = "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π"
            elif risk_score >= 45:
                category = "–í—ã—Å–æ–∫–∏–π"
            elif risk_score >= 20:
                category = "–°—Ä–µ–¥–Ω–∏–π"
            else:
                category = "–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π"
            
            risk_categories.append(category)
        
        return pd.DataFrame({
            'risk_score': risk_scores,
            'risk_category': risk_categories
        }, index=probabilities.index)
    
    def predict_with_risk(self, X: pd.DataFrame) -> Dict:
        """
        –ü–æ–ª–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∫–ª–∞—Å—Å—ã –∏ –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞
        """
        probabilities = self.predict_probabilities(X)
        predictions = self.predict(X)
        risks = self.calculate_risk_score(probabilities)
        
        return {
            'probabilities': probabilities,
            'predictions': predictions,
            'risk_scores': risks['risk_score'],
            'risk_categories': risks['risk_category']
        }
    
    def get_patient_report(self, X: pd.DataFrame, patient_idx: int = 0) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞
        """
        result = self.predict_with_risk(X.iloc[[patient_idx]])
        
        probabilities = result['probabilities'].iloc[0]
        predictions = result['predictions'].iloc[0]
        risk_score = result['risk_scores'].iloc[0]
        risk_category = result['risk_categories'].iloc[0]
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        disease_probs = [(disease, probabilities[disease]) 
                        for disease in self.diseases 
                        if disease in probabilities.index]
        disease_probs.sort(key=lambda x: x[1], reverse=True)
        
        report = f"""
{'='*80}
–û–¢–ß–ï–¢ –û –°–û–°–¢–û–Ø–ù–ò–ò –ó–î–û–†–û–í–¨–Ø –ü–ê–¶–ò–ï–ù–¢–ê
{'='*80}

–û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê –†–ò–°–ö–ê:
  –ë–∞–ª–ª —Ä–∏—Å–∫–∞: {risk_score:.1f}/100
  –ì—Ä—É–ø–ø–∞ —Ä–∏—Å–∫–∞: {risk_category}

–í–ï–†–û–Ø–¢–ù–û–°–¢–ò –ó–ê–ë–û–õ–ï–í–ê–ù–ò–ô (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ —É–±—ã–≤–∞–Ω–∏—é):
"""
        
        for disease, prob in disease_probs:
            pred = "–û–ë–ù–ê–†–£–ñ–ï–ù–û" if predictions[disease] == 1 else "–Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
            threshold = self.optimal_thresholds.get(disease, 0.5)
            
            # –í–∏–∑—É–∞–ª—å–Ω–∞—è —à–∫–∞–ª–∞
            bar_length = 30
            filled = int(prob * bar_length)
            bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
            
            report += f"\n  {disease}:\n"
            report += f"    [{bar}] {prob*100:.1f}%\n"
            report += f"    –°—Ç–∞—Ç—É—Å: {pred} (–ø–æ—Ä–æ–≥: {threshold:.2f})\n"
        
        # –¢–æ–ø-3 —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞
        if patient_idx < len(X):
            report += f"\n\n–ö–õ–Æ–ß–ï–í–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:\n"
            
            # –ù–∞—Ö–æ–¥–∏–º –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
            if disease_probs:
                top_disease = disease_probs[0][0]
                if top_disease in self.feature_importance:
                    top_features = self.feature_importance[top_disease].head(5)
                    
                    for _, row in top_features.iterrows():
                        feature = row['feature']
                        if feature in X.columns:
                            value = X.iloc[patient_idx][feature]
                            report += f"  ‚Ä¢ {feature}: {value}\n"
        
        report += f"\n{'='*80}\n"
        
        return report
    
    def save_models(self, filepath: str = 'cardio_classifier.pkl'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        model_data = {
            'models': self.models,
            'calibrated_models': self.calibrated_models,
            'scalers': self.scalers,
            'best_params': self.best_params,
            'optimal_thresholds': self.optimal_thresholds,
            'feature_importance': self.feature_importance,
            'diseases': self.diseases,
            'disease_weights': self.disease_weights
        }
        joblib.dump(model_data, filepath)
        print(f"\n‚úÖ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
    
    def load_models(self, filepath: str = 'cardio_classifier.pkl'):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        model_data = joblib.load(filepath)
        self.models = model_data['models']
        self.calibrated_models = model_data['calibrated_models']
        self.scalers = model_data['scalers']
        self.best_params = model_data['best_params']
        self.optimal_thresholds = model_data['optimal_thresholds']
        self.feature_importance = model_data['feature_importance']
        self.diseases = model_data['diseases']
        self.disease_weights = model_data['disease_weights']
        print(f"\n‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ {filepath}")
    
    def plot_feature_importance(self, top_n: int = 15):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è"""
        n_diseases = len(self.feature_importance)
        n_cols = 3
        n_rows = (n_diseases + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))
        axes = axes.flatten() if n_diseases > 1 else [axes]
        
        for idx, (disease, importance_df) in enumerate(self.feature_importance.items()):
            ax = axes[idx]
            top_features = importance_df.head(top_n)
            
            ax.barh(range(len(top_features)), top_features['importance'])
            ax.set_yticks(range(len(top_features)))
            ax.set_yticklabels(top_features['feature'])
            ax.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
            ax.set_title(f'{disease}', fontsize=10, fontweight='bold')
            ax.invert_yaxis()
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—É–±–ø–ª–æ—Ç—ã
        for idx in range(len(self.feature_importance), len(axes)):
            fig.delaxes(axes[idx])
        
        plt.tight_layout()
        plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
        print("\n‚úÖ –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ 'feature_importance.png'")
        plt.close()


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π pipeline –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    print("="*80)
    print("–°–ò–°–¢–ï–ú–ê –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò –ö–ê–†–î–ò–û–õ–û–ì–ò–ß–ï–°–ö–ò–• –ó–ê–ë–û–õ–ï–í–ê–ù–ò–ô")
    print("="*80)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    df = pd.read_csv('cardio_synthetic_dataset.csv')
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    print("\n2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
    classifier = MultiLabelCardioClassifier(random_state=42)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    X, y = classifier.prepare_data(df)
    print(f"   –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
    print(f"   –ö–ª–∞—Å—Å–æ–≤: {y.shape[1]}")
    
    # –û–±—É—á–µ–Ω–∏–µ
    print("\n4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    results = classifier.train(X, y, test_size=0.2)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print("\n5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    classifier.save_models('cardio_classifier.pkl')
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    classifier.plot_feature_importance(top_n=10)
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö
    print("\n7. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–∞—Ö...")
    print("\n" + "="*80)
    print("–ü–†–ò–ú–ï–†–´ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò")
    print("="*80)
    
    # –í—ã–±–∏—Ä–∞–µ–º 3 —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–∞
    test_indices = np.random.choice(len(X), size=3, replace=False)
    
    for idx in test_indices:
        report = classifier.get_patient_report(X, idx)
        print(report)
    
    print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    
    return classifier


if __name__ == "__main__":
    classifier = main()